{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVmsGWUFd-tP"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMJ4av3_YGjM",
        "outputId": "3a054f2e-d283-4aca-f25a-37f60c7afbf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUT0FSfTbvoc"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!pip3 install pyprind\n",
        "!pip3 install torchmetrics\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luGWILd9K9W9"
      },
      "source": [
        "ResNet - 50  and Vgg19 Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "y5YhkW3jE58O"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "import torch\n",
        "import os\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fij_DJiQY5JE"
      },
      "source": [
        "A template has been provided to help you. \n",
        "\n",
        "* You may or may not edit the `None` fields. There is no need to change anything else.\n",
        "* You might or might not have to add additional lines other than what is provided. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0M00nndzxYhw"
      },
      "outputs": [],
      "source": [
        " ''' Need to change transformations and Dense layer a little bit based on whether we using my model or vgg19\n",
        " * my model works in image size 32 x 32 but vgg19 works with 224 x 224 \n",
        " *  my model reduces image size by 8 x 8 but vgg19 changes it by 7 x 7 \n",
        " *  So in dense layer we need to change the input vector acc to that \n",
        " * Need not to specify , we need to change conv layer in forward Fn based on which model we use '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvfFGB6UbB8Z"
      },
      "outputs": [],
      "source": [
        "# Downloading and Preparing the Dataset\n",
        "\n",
        "!gdown --id 1oYnD7Izl3LVVzjEMyLxLklX30TKWHgGG\n",
        "!unzip /content/cifar-10.zip\n",
        "!rm -rf /content/cifar-10.zip\n",
        "!mv /content/cifar-10/sample_submission.csv /content/cifar-10/test_labels.csv\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdMFciI7WQkF"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchmetrics\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import pandas \n",
        "import numpy\n",
        "from sklearn import preprocessing\n",
        "import matplotlib\n",
        "\n",
        "import os\n",
        "import pyprind\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "\n",
        "PATH = \"/content/\" # Need to Add your google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xj-_3MeLVuz-"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CreateDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root_dir, mode='train'):\n",
        "        self.root_dir = root_dir\n",
        "        self.mode = mode\n",
        "\n",
        "        self.entry = pandas.read_csv(os.path.join(self.root_dir, f'{self.mode}_labels.csv'))\n",
        "        self.encoder = self._process_()\n",
        "        self.entry['label'] = self.encoder.transform(self.entry['label'])\n",
        "        self.transform = torchvision.transforms.Compose(\n",
        "            [\n",
        "                ''' Added some Transforms '''\n",
        "                torchvision.transforms.RandomInvert(),\n",
        "                torchvision.transforms.RandomHorizontalFlip(),\n",
        "                torchvision.transforms.RandomRotation(30),\n",
        "                #torchvision.transforms.Grayscale(),\n",
        "                torchvision.transforms.Resize((224,224)), \n",
        "                torchvision.transforms.ToTensor()\n",
        "            \n",
        "            ])\n",
        "        \n",
        "        self.trans = torchvision.transforms.Compose(\n",
        "            [\n",
        "                torchvision.transforms.Resize((224,224)), \n",
        "                torchvision.transforms.ToTensor()\n",
        "            ])\n",
        "\n",
        "    def _process_(self):\n",
        "        data = pandas.read_csv(os.path.join(self.root_dir, 'train_labels.csv'))\n",
        "        encoder = preprocessing.LabelEncoder()\n",
        "        encoder.fit(data['label'])\n",
        "        return encoder\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        index = index if index !=0 else 1\n",
        "        data = self.entry.iloc[index]\n",
        "        img_path = '/content/cifar-10/'+ self.mode + '/' + str(index) + '.png'\n",
        "        image = plt.imread(img_path) # Read Image?    ( Bro here index of images are random , so what to do ?)  - yes done\n",
        "        image = Image.fromarray(image, \"RGB\")\n",
        "        image = self.trans(image)\n",
        "        label = data[1]                 # Read Label? - yes done \n",
        "        return image, label\n",
        "      \n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.entry)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVcmwdD1pF79"
      },
      "outputs": [],
      "source": [
        "k = CreateDataset(\"/content/cifar-10\")\n",
        "trainloader22 = torch.utils.data.DataLoader(k, batch_size=5000, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBf_Oqs23EB8"
      },
      "outputs": [],
      "source": [
        "# getting some info about image\n",
        "sizes = []\n",
        "for image in os.listdir(\"/content/cifar-10/train\"):\n",
        "  image = plt.imread(\"/content/cifar-10/train/\"+image)\n",
        "  sizes.append(image.shape)\n",
        "pandas.Series(sizes).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qw-boN_Iv3vr"
      },
      "outputs": [],
      "source": [
        "sizes = []\n",
        "for image in os.listdir(\"/content/cifar-10/test\"):\n",
        "  image = plt.imread(\"/content/cifar-10/test/\"+image)\n",
        "  sizes.append(image.shape)\n",
        "pandas.Series(sizes).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNSsfBPHF476"
      },
      "outputs": [],
      "source": [
        "# Downloading cifar10 data "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms.transforms import RandomCrop\n",
        "transform = transforms.Compose(\n",
        "    [#transforms.Grayscale(),\n",
        "     transforms.ToTensor(),\n",
        "     ])\n",
        "transform_test = transforms.Compose(\n",
        "    [transforms.ToTensor()\n",
        "    ])"
      ],
      "metadata": {
        "id": "R6WP9cSV0H1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ns6n-e4_ANFm"
      },
      "outputs": [],
      "source": [
        "# code to get cifar10 dataset:\n",
        "\n",
        "x_train  = datasets.CIFAR10(root='./data/',train=True,download=True,transform=transform)\n",
        "x_test = datasets.CIFAR10(root='./data/',train=False,download=True,transform=transform_test)\n",
        "clear_output() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMFLk_gUANnI"
      },
      "outputs": [],
      "source": [
        "conv_vgg19 = nn.Sequential(\n",
        "    \n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.MaxPool2d(kernel_size=(2,2),stride=(2,2) ),\n",
        "\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.MaxPool2d(kernel_size=(2,2),stride=(2,2) ),\n",
        "\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.MaxPool2d(kernel_size=(2,2),stride=(2,2) ),\n",
        "\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.MaxPool2d(kernel_size=(2,2),stride=(2,2) ),\n",
        "\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.MaxPool2d(kernel_size=(2,2),stride=(2,2) ),\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhpnlVPlWfVN"
      },
      "outputs": [],
      "source": [
        "class Custom_Model(nn.Module):\n",
        "      def __init__(self):\n",
        "        super(Custom_Model, self).__init__() \n",
        "\n",
        "        self.convlayer = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d(kernel_size=(2,2),stride=(2,2) ),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(kernel_size=(2,2),stride=(2,2) ),\n",
        "\n",
        "        )\n",
        "\n",
        "        #self.conv_vgg_19 = conv_vgg19\n",
        "\n",
        "        self.dense_layer = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(4*224*224, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512,128),                   # Dense layer\n",
        "            #nn.ReLU(),\n",
        "            #nn.Linear(128,64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128,10),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "      def forward(self, x): # x is the input image\n",
        "        #y = self.conv_vgg_19(x)\n",
        "        #print(x.shape)\n",
        "        y = self.convlayer(x)\n",
        "        y = self.dense_layer(x)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYHk4v5-WrfF"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "    def __init__(self, data):\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.trainloader, self.validloader, self.testloader = self.get_iterator(data)\n",
        "        \n",
        "        self.model = self.get_model().to(self.device)\n",
        "        self.criterion = self.get_criterion().to(self.device)\n",
        "        self.optimizer = self.get_optimizer()\n",
        "\n",
        "        self.accuracy_valid = torchmetrics.Accuracy().to(self.device)\n",
        "        self.accuracy_train = torchmetrics.Accuracy().to(self.device)\n",
        "        self.accuracy_test = torchmetrics.Accuracy().to(self.device)\n",
        "\n",
        "        self.train_loss = []\n",
        "        self.train_metrics = []\n",
        "        self.valid_loss = []\n",
        "        self.valid_metrics = []\n",
        "\n",
        "        self.epochs = 2\n",
        "\n",
        "    def get_iterator(self, data):\n",
        "        train, valid, test = data\n",
        "        trainloader = torch.utils.data.DataLoader(train, batch_size=500, shuffle=True, drop_last=True)      # Choosen batch_size - chosen 10\n",
        "        validloader = torch.utils.data.DataLoader(valid, batch_size=500, shuffle=False, drop_last=True)     # Choosen batch_size - chosen 10\n",
        "        testloader = torch.utils.data.DataLoader(test, batch_size=100, shuffle=False)                       # Choosen batch_size - chosen 10\n",
        "        return trainloader, validloader, testloader\n",
        "\n",
        "    def get_criterion(self):\n",
        "        return nn.CrossEntropyLoss()                                                                         # Added loss-(CrossEntropyLoss)\n",
        "    \n",
        "    def get_optimizer(self):\n",
        "        return torch.optim.Adam(self.model.parameters(), lr=0.01)                                                       # Added optimizer(Adam)\n",
        "\n",
        "    def get_model(self):\n",
        "        model = Custom_Model()                                                                                # Added model\n",
        "        return model\n",
        "\n",
        "    def save(self, epoch):\n",
        "        torch.save({\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            }, os.path.join(PATH, \"model.pth\"))\n",
        "        \n",
        "    def load(self):\n",
        "        if os.path.exists(os.path.join(PATH, \"model.pth\")):\n",
        "            checkpoints = torch.load(os.path.join(self.args.checkpoint, \"model.pth\"), map_location=self.device)\n",
        "            self.model.load_state_dict(checkpoints['model_state_dict'])\n",
        "            self.optimizer.load_state_dict(checkpoints['optimizer_state_dict'])\n",
        "\n",
        "    def train(self):\n",
        "        epoch_loss = 0\n",
        "        epoch_metrics = {}\n",
        "\n",
        "        self.model.train()\n",
        "\n",
        "        with torch.autograd.set_detect_anomaly(True):\n",
        "            bar = pyprind.ProgBar(len(self.trainloader), bar_char='█')\n",
        "            for index, (image, label) in enumerate(self.trainloader):\n",
        "                image = image.to(self.device)\n",
        "                label = label.to(self.device)\n",
        "                #print(image.shape)\n",
        "                #image = image.reshape(image.shape[0],-1)\n",
        "                self.optimizer.zero_grad()\n",
        "                \n",
        "                output = self.model(image) # Forward Pass\n",
        "\n",
        "                loss = self.criterion(output,label) # Evaluating Loss\n",
        "      \n",
        "                loss.backward() # Back Propogation\n",
        "\n",
        "                _,predcitions = output.max(1)\n",
        "                self.accuracy_train(predcitions,label)\n",
        "\n",
        "                self.optimizer.step()\n",
        "                bar.update()\n",
        "\n",
        "        accuracy = self.accuracy_train.compute()\n",
        "        self.accuracy_train.reset()\n",
        "        return epoch_loss, accuracy\n",
        "\n",
        "    def evaluate(self):\n",
        "        epoch_loss = 0\n",
        "        epoch_metrics = {}        \n",
        "\n",
        "        with torch.autograd.set_detect_anomaly(True):\n",
        "           \n",
        "            bar = pyprind.ProgBar(len(self.validloader), bar_char='█')\n",
        "            for index, (image, label) in enumerate(self.validloader):\n",
        "                image = image.to(self.device)\n",
        "                label = label.to(self.device)\n",
        "                #image = image.reshape(image.shape[0],-1)\n",
        "\n",
        "                output =self.model(image).to(self.device)  \n",
        "\n",
        "                loss = self.criterion(output,label) \n",
        "\n",
        "                _,predcitions = output.max(1)\n",
        "                self.accuracy_valid(predcitions,label)\n",
        "\n",
        "                bar.update()\n",
        "                epoch_loss = loss\n",
        "\n",
        "            accuracy = self.accuracy_valid.compute()\n",
        "            self.accuracy_valid.reset()\n",
        "            return epoch_loss, accuracy\n",
        "\n",
        "    def test(self):\n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "        outputs = numpy.array([])\n",
        "\n",
        "        with torch.autograd.set_detect_anomaly(True):\n",
        "            bar = pyprind.ProgBar(len(self.testloader), bar_char='█')\n",
        "            for index, (image, label) in enumerate(self.testloader):\n",
        "                image = image.to(self.device)\n",
        "                label = label.to(self.device)\n",
        "                #image = image.reshape(image.shape[0],-1)\n",
        "\n",
        "                output = self.model(image)   \n",
        "\n",
        "                _,pred = output.max(1)\n",
        "               \n",
        "                pred = pred.cpu().numpy()\n",
        "                outputs = numpy.append(outputs,pred)\n",
        "               \n",
        "\n",
        "                #print(outputs.shape)\n",
        "                bar.update()\n",
        "        outputs.reshape((1,10000)) \n",
        "        return outputs\n",
        "    \n",
        "    def fit(self):\n",
        "\n",
        "        for epoch in range(1, self.epochs+1, 1):\n",
        "\n",
        "            epoch_train_loss, epoch_train_metrics = self.train()\n",
        "\n",
        "            self.train_loss.append(epoch_train_loss)\n",
        "            self.train_metrics.append(epoch_train_metrics)\n",
        "\n",
        "            epoch_valid_loss, epoch_valid_metrics = self.evaluate()\n",
        "            \n",
        "            self.valid_loss.append(epoch_valid_loss)\n",
        "            self.valid_metrics.append(epoch_valid_metrics) \n",
        "\n",
        "            print(f'Epoch {epoch}/{self.epochs+1}: Train Loss = {epoch_train_loss} | Validation Loss = {epoch_valid_loss}')\n",
        "            print(f'train accuracy : {epoch_train_metrics}   valid accuracy : {epoch_valid_metrics} ')\n",
        "\n",
        "            if epoch_valid_metrics >= max(self.valid_metrics):\n",
        "                self.save(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2VnYXVYYaqF",
        "outputId": "44a57131-b321-410f-a4dd-943934f85006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:26\n",
            "0% [██████████] 100% | ETA: 00:00:00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3: Train Loss = 0 | Validation Loss = 2.3025999069213867\n",
            "train accuracy : 0.10048888623714447   valid accuracy : 0.10019999742507935 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Total time elapsed: 00:00:02\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:25\n",
            "0% [██████████] 100% | ETA: 00:00:00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/3: Train Loss = 0 | Validation Loss = 2.302568197250366\n",
            "train accuracy : 0.09857777506113052   valid accuracy : 0.09780000150203705 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Total time elapsed: 00:00:02\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " [5. 5. 5. ... 5. 5. 5.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Total time elapsed: 00:00:06\n"
          ]
        }
      ],
      "source": [
        "train_data = CreateDataset(\"/content/cifar-10\")                 \n",
        "train_data, valid_data = torch.utils.data.random_split(train_data, [len(train_data)-len(train_data)//10, len(train_data)//10])\n",
        "test_data = CreateDataset(\"/content/cifar-10\",'test')             \n",
        "data = (train_data, valid_data, test_data)\n",
        "\n",
        "trainer = Trainer(data)\n",
        "trainer.fit()\n",
        "\n",
        "outputs = trainer.test()\n",
        "print(\"\\n\",outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekRNT6ZmdUOO"
      },
      "outputs": [],
      "source": [
        "'''VGG19 Arch\n",
        "\n",
        "Conv3x3 (64)\n",
        "Conv3x3 (64)\n",
        "MaxPool\n",
        "Conv3x3 (128)\n",
        "Conv3x3 (128)\n",
        "MaxPool\n",
        "Conv3x3 (256)\n",
        "Conv3x3 (256)\n",
        "Conv3x3 (256)\n",
        "Conv3x3 (256)\n",
        "MaxPool\n",
        "Conv3x3 (512)\n",
        "Conv3x3 (512)\n",
        "Conv3x3 (512)\n",
        "Conv3x3 (512)\n",
        "MaxPool\n",
        "Conv3x3 (512)\n",
        "Conv3x3 (512)\n",
        "Conv3x3 (512)\n",
        "Conv3x3 (512)\n",
        "MaxPool\n",
        "Fully Connected (4096)    \n",
        "Fully Connected (4096)    Dense layer write acc to your model\n",
        "Fully Connected (1000)\n",
        "SoftMax\n",
        "Resize the images to (224,224,3)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caoqe45rT_rw"
      },
      "outputs": [],
      "source": [
        "conv_vgg19 = nn.Sequential(\n",
        "    \n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.MaxPool2d(kernel_size=(2,2),stride=(2,2) ),\n",
        "\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.MaxPool2d(kernel_size=(2,2),stride=(2,2) ),\n",
        "\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.MaxPool2d(kernel_size=(2,2),stride=(2,2) ),\n",
        "\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.MaxPool2d(kernel_size=(2,2),stride=(2,2) ),\n",
        "\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride = (1,1) , padding = (1,1) ),\n",
        "            nn.MaxPool2d(kernel_size=(2,2),stride=(2,2) ),\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsifgV1BrfNj"
      },
      "outputs": [],
      "source": [
        "# output = floor[(input + 2*padding — kernel) / stride + 1]\n",
        "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIPzKejhHqJT"
      },
      "outputs": [],
      "source": [
        "# a class to build the basic blocks\n",
        "class BlockBuilder(nn.Module):\n",
        "    def __init__(self,inp_cha,out_cha,stride=1,kernel=3):\n",
        "      super().__init__()\n",
        "\n",
        "      self.stride = stride\n",
        "      self.kernel = kernel\n",
        "      self.inp = inp_cha\n",
        "      self.out = out_cha\n",
        "\n",
        "      # here I have defined the alternate path as path2\n",
        "\n",
        "      if self.stride != 1 or self.inp != self.out:\n",
        "        self.path2 = nn.Sequential( nn.Conv2d(self.inp, self.out, kernel_size=1, stride=self.stride),\n",
        "                                   nn.BatchNorm2d(self.out).to(dev)\n",
        "        )\n",
        "      else:\n",
        "        self.path2 = nn.Sequential().to(dev)\n",
        "\n",
        "      # here I am going to define the conv layers for the actual path\n",
        "\n",
        "      self.actual_layers = nn.Sequential(\n",
        "          nn.Conv2d(self.inp, self.out//4, kernel_size=1, stride=1).to(dev),\n",
        "          nn.BatchNorm2d(self.out//4),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d( self.out//4, self.out//4, kernel_size=3, stride=self.stride,padding=1).to(dev),\n",
        "          nn.BatchNorm2d(self.out//4),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d( self.out//4, self.out, kernel_size=1, stride=1).to(dev),\n",
        "          nn.BatchNorm2d(self.out),\n",
        "          nn.ReLU(),\n",
        "      ).to(dev)\n",
        "\n",
        "    def forward(self,input):\n",
        "\n",
        "        input_path2 = self.path2(input).to(dev)\n",
        "        output = self.actual_layers(input).to(dev)\n",
        "        combined_output = (output + input_path2).to(dev)\n",
        "        return nn.ReLU()(combined_output).to(dev)\n",
        "\n",
        "# Block Builder finished"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmO_CENkXxuN"
      },
      "outputs": [],
      "source": [
        "# here I am going to buid the whole network\n",
        "\n",
        "class network(nn.Module):\n",
        "    def __init__(self,block=BlockBuilder,arch=[64, 256, 512, 1024, 2048],repeaters=[3,4,6,3],input_channels=3,strides=[1,2,1,2],classes=10):\n",
        "        super(network,self).__init__()\n",
        "\n",
        "        self.inpc = input_channels\n",
        "        self.arch = arch\n",
        "        self.repeaters = repeaters\n",
        "        self.strides = strides\n",
        "        self.cl = classes\n",
        "\n",
        "        # here I have defined the first layer0\n",
        "\n",
        "        self.layero = nn.Sequential(\n",
        "            nn.Conv2d(self.inpc, 64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "            )\n",
        "        self.dynamic_layers = {}\n",
        "        # here I am defining the blocks\n",
        "        self.dlayers = nn.Sequential()\n",
        "\n",
        "        for i in range(len(self.arch)-1):\n",
        "          self.dlayers.add_module(f'conv{i}', block(self.arch[i],self.arch[i+1], stride=self.strides[i]))\n",
        "          for j in range(0,self.repeaters[i]-1):\n",
        "              self.dlayers.add_module(f'conv{i}+{j}', block(self.arch[i+1],self.arch[i+1], stride=1))\n",
        "          self.dlayers.to(dev)\n",
        "\n",
        "            # definfig the Fc layer here\n",
        "          self.avgpool = torch.nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "          self.fc = nn.Sequential(\n",
        "              nn.Flatten(),\n",
        "              nn.Linear(self.arch[4],4096),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(4096,512),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(512,64),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(64,10),\n",
        "              nn.Softmax(dim=1),\n",
        "          )\n",
        "\n",
        "    def forward(self,input_s):\n",
        "        input_s = self.layero(input_s)\n",
        "        input_s = self.dlayers(input_s)\n",
        "        input_s = self.avgpool(input_s)\n",
        "        input_s = self.fc(input_s)\n",
        "        return input_s\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arEWsURx1Rxz"
      },
      "outputs": [],
      "source": [
        "restnet_model = network().to(torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnuvADVCf87a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShUExGpyT9ih",
        "outputId": "b1bbee75-3aaf-4d38-aa50-13674889c6fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "network(\n",
              "  (layero): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
              "    (1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): ReLU()\n",
              "  )\n",
              "  (dlayers): ModuleList(\n",
              "    (conv0): BlockBuilder(\n",
              "      (path2): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (actual_layers): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (8): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (conv0+0): BlockBuilder(\n",
              "      (path2): Sequential()\n",
              "      (actual_layers): Sequential(\n",
              "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (8): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (conv0+1): BlockBuilder(\n",
              "      (path2): Sequential()\n",
              "      (actual_layers): Sequential(\n",
              "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (8): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (conv1): BlockBuilder(\n",
              "      (path2): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (actual_layers): Sequential(\n",
              "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (8): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (conv1+0): BlockBuilder(\n",
              "      (path2): Sequential()\n",
              "      (actual_layers): Sequential(\n",
              "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (8): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (conv1+1): BlockBuilder(\n",
              "      (path2): Sequential()\n",
              "      (actual_layers): Sequential(\n",
              "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (8): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (conv1+2): BlockBuilder(\n",
              "      (path2): Sequential()\n",
              "      (actual_layers): Sequential(\n",
              "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (8): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (conv2): BlockBuilder(\n",
              "      (path2): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (actual_layers): Sequential(\n",
              "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (8): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (conv2+0): BlockBuilder(\n",
              "      (path2): Sequential()\n",
              "      (actual_layers): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (8): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (conv2+1): BlockBuilder(\n",
              "      (path2): Sequential()\n",
              "      (actual_layers): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (8): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (conv2+2): BlockBuilder(\n",
              "      (path2): Sequential()\n",
              "      (actual_layers): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (8): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (conv2+3): BlockBuilder(\n",
              "      (path2): Sequential()\n",
              "      (actual_layers): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (8): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (conv2+4): BlockBuilder(\n",
              "      (path2): Sequential()\n",
              "      (actual_layers): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (8): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (conv3): BlockBuilder(\n",
              "      (path2): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (actual_layers): Sequential(\n",
              "        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (8): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (conv3+0): BlockBuilder(\n",
              "      (path2): Sequential()\n",
              "      (actual_layers): Sequential(\n",
              "        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (8): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (conv3+1): BlockBuilder(\n",
              "      (path2): Sequential()\n",
              "      (actual_layers): Sequential(\n",
              "        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU()\n",
              "        (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (8): ReLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (fc): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=4096, out_features=512, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Linear(in_features=512, out_features=64, bias=True)\n",
              "    (6): ReLU()\n",
              "    (7): Linear(in_features=64, out_features=10, bias=True)\n",
              "    (8): Softmax(dim=1)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "restnet_model"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}